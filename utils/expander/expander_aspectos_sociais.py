import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from typing import Dict, List, Any, Optional, Union, Tuple
from utils.estatisticas.analise_aspectos_sociais import (
    calcular_estatisticas_distribuicao,
    analisar_correlacao_categorias,
    analisar_distribuicao_regional,
    calcular_estatisticas_por_categoria
)
from utils.explicacao.explicacao_aspectos_sociais import (
    get_interpretacao_associacao,
    get_interpretacao_variabilidade_regional,
    get_analise_concentracao
)
from utils.mappings import get_mappings
from utils.helpers.regiao_utils import obter_regiao_do_estado

# Obter limiares dos mapeamentos centralizados
mappings = get_mappings()
mappings = get_mappings()
LIMIARES_ESTATISTICOS = mappings.get('limiares_estatisticos', {})

# Constantes para classifica√ß√£o de variabilidade
LIMITE_VARIABILIDADE_BAIXA = LIMIARES_ESTATISTICOS.get('variabilidade_baixa', 15)
LIMITE_VARIABILIDADE_MODERADA = LIMIARES_ESTATISTICOS.get('variabilidade_moderada', 30)

# Constantes para classifica√ß√£o de correla√ß√£o
LIMITE_CORRELACAO_FRACA = LIMIARES_ESTATISTICOS.get('correlacao_fraca', 0.3)
LIMITE_CORRELACAO_MODERADA = LIMIARES_ESTATISTICOS.get('correlacao_moderada', 0.7)
LIMITE_CORRELACAO_FORTE = LIMIARES_ESTATISTICOS.get('correlacao_forte', 0.8)

def criar_expander_analise_correlacao(
    df_correlacao: pd.DataFrame, 
    var_x: str, 
    var_y: str, 
    var_x_plot: str, 
    var_y_plot: str, 
    variaveis_sociais: Dict[str, Dict[str, Any]]
) -> None:
    """
    Cria um expander com an√°lise estat√≠stica detalhada da correla√ß√£o entre dois aspectos sociais.
    
    Par√¢metros:
    -----------
    df_correlacao : DataFrame
        DataFrame com dados correlacionados
    var_x : str
        C√≥digo da vari√°vel original para o eixo X
    var_y : str
        C√≥digo da vari√°vel original para o eixo Y
    var_x_plot : str
        Nome da vari√°vel de plotagem para o eixo X (pode incluir sufixo _NOME)
    var_y_plot : str
        Nome da vari√°vel de plotagem para o eixo Y (pode incluir sufixo _NOME)
    variaveis_sociais : Dict
        Dicion√°rio com informa√ß√µes sobre as vari√°veis sociais
    """
    # Validar entrada
    if df_correlacao is None or df_correlacao.empty:
        return
    
    # Verificar se as vari√°veis existem no dicion√°rio de mapeamentos
    if var_x not in variaveis_sociais or var_y not in variaveis_sociais:
        return
        
    with st.expander("Ver an√°lise estat√≠stica detalhada"):
        try:
            # Calcular m√©tricas de correla√ß√£o
            metricas = analisar_correlacao_categorias(df_correlacao, var_x_plot, var_y_plot)
            
            # T√≠tulo principal
            st.write(f"### An√°lise de associa√ß√£o entre {variaveis_sociais[var_x]['nome']} e {variaveis_sociais[var_y]['nome']}")
            
            # Dividir em colunas para organizar a visualiza√ß√£o
            col1, col2 = st.columns(2)
            
            with col1:
                # Resumo da associa√ß√£o
                _mostrar_resumo_associacao(metricas, variaveis_sociais, var_x, var_y)
            
            with col2:
                # M√©tricas estat√≠sticas
                _mostrar_metricas_estatisticas(metricas)
                
            # Mostrar interpreta√ß√£o contextualizada da associa√ß√£o
            st.write("#### Interpreta√ß√£o contextualizada:")
            interpretacao = get_interpretacao_associacao(
                metricas['coeficiente'],
                variaveis_sociais[var_x]['nome'],
                variaveis_sociais[var_y]['nome']
            )
            st.write(interpretacao)
            
            # An√°lise por categorias
            _mostrar_analise_categorias(df_correlacao, var_x_plot, var_y_plot, variaveis_sociais, var_x, var_y)
            
            # Verificar se temos uma tabela de conting√™ncia v√°lida
            if not metricas['tabela_contingencia'].empty:
                st.write("#### Tabela de conting√™ncia (percentuais por linha):")
                
                # Criar tabela normalizada por linha
                tabela_normalizada = metricas['tabela_contingencia'].copy()
                somas_linha = tabela_normalizada.sum(axis=1)
                tabela_normalizada = tabela_normalizada.div(somas_linha, axis=0) * 100
                
                # Formatar para exibi√ß√£o
                st.dataframe(tabela_normalizada.round(1).fillna(0))
        
        except Exception as e:
            st.error(f"Erro ao gerar an√°lise de correla√ß√£o: {str(e)}")


def criar_expander_dados_distribuicao(
    contagem_aspecto: pd.DataFrame, 
    aspecto_social: str, 
    variaveis_sociais: Dict[str, Dict[str, Any]]
) -> None:
    """
    Cria um expander com dados detalhados sobre a distribui√ß√£o de um aspecto social.
    
    Par√¢metros:
    -----------
    contagem_aspecto : DataFrame
        DataFrame com contagem de candidatos por categoria
    aspecto_social : str
        C√≥digo do aspecto social analisado
    variaveis_sociais : Dict
        Dicion√°rio com informa√ß√µes sobre vari√°veis sociais
    """
    # Validar entrada
    if contagem_aspecto is None or contagem_aspecto.empty:
        return
    
    # Verificar se o aspecto social existe no dicion√°rio
    if aspecto_social not in variaveis_sociais:
        return
        
    with st.expander("Ver dados detalhados"):
        try:
            # Calcular estat√≠sticas de distribui√ß√£o
            estatisticas = calcular_estatisticas_distribuicao(contagem_aspecto)
            
            # Nome amig√°vel do aspecto social
            nome_aspecto = variaveis_sociais[aspecto_social]["nome"]
            
            # Mostrar estat√≠sticas principais
            _mostrar_estatisticas_principais_distribuicao(estatisticas, nome_aspecto)
            
            # Mostrar an√°lise de concentra√ß√£o e equidade
            _mostrar_analise_concentracao_equidade(estatisticas, nome_aspecto)
            
            # Calcular e mostrar percentuais acumulados
            _mostrar_analise_concentracao_percentual(contagem_aspecto)
            
            # Op√ß√£o para exibir tabela completa
            if st.checkbox("Mostrar tabela completa", key="show_full_table_dist"):
                st.write("### Tabela completa")
                
                # Formatar colunas num√©ricas
                df_display = contagem_aspecto.copy()
                st.dataframe(
                    df_display,
                    column_config={
                        'Quantidade': st.column_config.NumberColumn(
                            'Quantidade',
                            format="%d"
                        ),
                        'Percentual': st.column_config.NumberColumn(
                            'Percentual (%)',
                            format="%.2f%%"
                        )
                    }
                )
                
                # Op√ß√£o para download
                csv = df_display.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "Download dos dados (CSV)",
                    csv,
                    f"distribuicao_{aspecto_social}.csv",
                    "text/csv",
                    key='download_distribuicao_csv'
                )
                
        except Exception as e:
            st.error(f"Erro ao gerar an√°lise de distribui√ß√£o: {str(e)}")


def criar_expander_analise_regional(
    df_por_estado: pd.DataFrame, 
    aspecto_social: str, 
    categoria_selecionada: str, 
    variaveis_sociais: Dict[str, Dict[str, Any]], 
    tipo_localidade: str = "estado"
) -> None:
    """
    Cria um expander com an√°lise detalhada da distribui√ß√£o regional de uma categoria espec√≠fica.
    
    Par√¢metros:
    -----------
    df_por_estado : DataFrame
        DataFrame com os dados por estado/regi√£o
    aspecto_social : str
        C√≥digo do aspecto social analisado
    categoria_selecionada : str
        Nome da categoria selecionada para an√°lise
    variaveis_sociais : Dict
        Dicion√°rio com mapeamentos e configura√ß√µes
    tipo_localidade : str, default="estado"
        Tipo de localidade (estado ou regi√£o)
    """
    # Validar entrada
    if df_por_estado is None or df_por_estado.empty:
        return
    
    # Verificar se o aspecto social existe no dicion√°rio
    if aspecto_social not in variaveis_sociais:
        return
        
    with st.expander(f"Ver an√°lise regional detalhada"):
        try:
            # Analisar distribui√ß√£o regional para a categoria selecionada
            analise = analisar_distribuicao_regional(df_por_estado, aspecto_social, categoria_selecionada)
            
            # Nome amig√°vel do aspecto social
            nome_aspecto = variaveis_sociais[aspecto_social]["nome"]
            
            # T√≠tulo e seletores de categoria
            _configurar_titulo_analise_regional(
                df_por_estado, aspecto_social, categoria_selecionada, nome_aspecto, tipo_localidade
            )
            
            # Mostrar estat√≠sticas gerais
            _mostrar_estatisticas_regionais(analise, categoria_selecionada, tipo_localidade)
            
            # Mostrar variabilidade regional
            _mostrar_variabilidade_regional(analise, nome_aspecto, categoria_selecionada)
            
            # Mostrar ranking de estados/regi√µes
            _mostrar_ranking_localidades(df_por_estado, categoria_selecionada, analise, tipo_localidade)
            
            # Se for por estado, adicionar an√°lise por regi√£o
            if tipo_localidade.lower() == "estado":
                _mostrar_analise_por_regiao(df_por_estado, categoria_selecionada, nome_aspecto)
            
        except Exception as e:
            st.error(f"Erro ao gerar an√°lise regional: {str(e)}")


def criar_expander_dados_completos_estado(
    df_dados: pd.DataFrame, 
    tipo_localidade: str = "estado"
) -> None:
    """
    Cria um expander com an√°lise completa e profissional dos dados por estado/regi√£o.
    
    Par√¢metros:
    -----------
    df_dados : DataFrame
        DataFrame com os dados para a tabela
    tipo_localidade : str, default="estado"
        Tipo de localidade (estado ou regi√£o)
    """
    # Validar entrada
    if df_dados is None or df_dados.empty:
        return
        
    with st.expander(f"üìä An√°lise completa dos dados por {tipo_localidade}"):
        try:
            # Verificar se temos dados suficientes
            colunas_necessarias = ['Estado', 'Categoria', 'Percentual']
            if not all(col in df_dados.columns for col in colunas_necessarias):
                st.warning(f"Dados insuficientes para an√°lise completa. Colunas necess√°rias n√£o encontradas.")
                return
            
            # Se√ß√£o 1: Resumo executivo
            st.markdown("### üìà Resumo Executivo")
            _mostrar_resumo_executivo(df_dados, tipo_localidade)
            
            st.markdown("---")
            
            # Se√ß√£o 2: An√°lise estat√≠stica por categoria
            st.markdown("### üîç An√°lise Estat√≠stica por Categoria")
            _mostrar_analise_estatistica_categorias(df_dados, tipo_localidade)
            
            st.markdown("---")
            
            # Se√ß√£o 3: Ranking e disparidades regionais
            st.markdown("### üèÜ Ranking e Disparidades Regionais")
            _mostrar_ranking_disparidades(df_dados, tipo_localidade)
            
            st.markdown("---")
            
            # Se√ß√£o 4: Insights e padr√µes identificados
            st.markdown("### üí° Insights e Padr√µes Identificados")
            _mostrar_insights_padroes(df_dados, tipo_localidade)
            
            st.markdown("---")
            
            # Se√ß√£o 5: Tabela interativa com filtros
            st.markdown("### üìã Dados Detalhados - Tabela Interativa")
            _mostrar_tabela_interativa(df_dados, tipo_localidade)
            
            st.markdown("---")
            
            # Se√ß√£o 6: Downloads e exporta√ß√£o
            st.markdown("### üì• Downloads e Exporta√ß√£o")
            _mostrar_opcoes_download(df_dados, tipo_localidade)
            
        except Exception as e:
            st.error(f"Erro ao gerar an√°lise completa: {str(e)}")
            # Fallback para a vers√£o b√°sica
            st.warning("Exibindo vers√£o simplificada dos dados:")
            _mostrar_tabela_basica(df_dados, tipo_localidade)


# Fun√ß√µes auxiliares para a an√°lise completa de dados por estado/regi√£o

def _mostrar_resumo_executivo(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra um resumo executivo dos dados por estado/regi√£o.
    """
    try:
        # C√°lculos b√°sicos
        total_localidades = df_dados['Estado'].nunique()
        total_categorias = df_dados['Categoria'].nunique()
        
        # Estat√≠sticas gerais
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                label=f"Total de {tipo_localidade}s",
                value=total_localidades
            )
        
        with col2:
            st.metric(
                label="Categorias analisadas",
                value=total_categorias
            )
        
        with col3:
            media_geral = df_dados['Percentual'].mean()
            st.metric(
                label="Percentual m√©dio",
                value=f"{media_geral:.1f}%"
            )
        
        # Insights principais
        st.markdown("**üìã Principais observa√ß√µes:**")
        
        # Encontrar extremos
        max_valor = df_dados.loc[df_dados['Percentual'].idxmax()]
        min_valor = df_dados.loc[df_dados['Percentual'].idxmin()]
        
        st.write(f"‚Ä¢ **Maior percentual:** {max_valor['Percentual']:.1f}% ({max_valor['Categoria']} - {max_valor['Estado']})")
        st.write(f"‚Ä¢ **Menor percentual:** {min_valor['Percentual']:.1f}% ({min_valor['Categoria']} - {min_valor['Estado']})")
        
        # Variabilidade
        coef_variacao = (df_dados['Percentual'].std() / df_dados['Percentual'].mean()) * 100
        if coef_variacao < 20:
            variabilidade = "baixa"
        elif coef_variacao < 40:
            variabilidade = "moderada"
        else:
            variabilidade = "alta"
        
        st.write(f"‚Ä¢ **Variabilidade entre {tipo_localidade}s:** {variabilidade} (CV = {coef_variacao:.1f}%)")
        
    except Exception as e:
        st.error(f"Erro ao gerar resumo executivo: {str(e)}")


def _mostrar_analise_estatistica_categorias(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra an√°lise estat√≠stica detalhada por categoria.
    """
    try:
        # An√°lise por categoria
        categorias = df_dados['Categoria'].unique()
        
        if len(categorias) > 1:
            categoria_selecionada = st.selectbox(
                "Selecione uma categoria para an√°lise detalhada:",
                categorias,
                key="analise_categoria_detalhada"
            )
            
            df_categoria = df_dados[df_dados['Categoria'] == categoria_selecionada]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**Estat√≠sticas de '{categoria_selecionada}':**")
                
                # Estat√≠sticas descritivas
                stats = df_categoria['Percentual'].describe()
                st.write(f"‚Ä¢ **M√©dia:** {stats['mean']:.1f}%")
                st.write(f"‚Ä¢ **Mediana:** {stats['50%']:.1f}%")
                st.write(f"‚Ä¢ **Desvio padr√£o:** {stats['std']:.1f}%")
                st.write(f"‚Ä¢ **Amplitude:** {stats['max'] - stats['min']:.1f}%")
                
                # Percentis
                st.markdown("**Percentis:**")
                st.write(f"‚Ä¢ P25: {stats['25%']:.1f}%")
                st.write(f"‚Ä¢ P75: {stats['75%']:.1f}%")
                
            with col2:
                st.markdown(f"**{tipo_localidade.capitalize()}s extremos:**")
                
                # Top 3 e bottom 3
                top_3 = df_categoria.nlargest(3, 'Percentual')
                bottom_3 = df_categoria.nsmallest(3, 'Percentual')
                
                st.markdown("**üîù Maiores percentuais:**")
                for i, row in top_3.iterrows():
                    st.write(f"‚Ä¢ {row['Estado']}: {row['Percentual']:.1f}%")
                
                st.markdown("**üîª Menores percentuais:**")
                for i, row in bottom_3.iterrows():
                    st.write(f"‚Ä¢ {row['Estado']}: {row['Percentual']:.1f}%")
        
        else:
            st.info("An√°lise dispon√≠vel apenas quando h√° m√∫ltiplas categorias.")
    
    except Exception as e:
        st.error(f"Erro ao gerar an√°lise estat√≠stica: {str(e)}")


def _mostrar_ranking_disparidades(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra ranking completo e an√°lise de disparidades.
    """
    try:
        # Calcular m√©dias por estado/regi√£o
        df_medias = df_dados.groupby('Estado')['Percentual'].agg(['mean', 'std', 'count']).reset_index()
        df_medias.columns = ['Estado', 'Media', 'Desvio', 'Categorias']
        df_medias = df_medias.sort_values('Media', ascending=False)
        
        # Ranking
        st.markdown(f"**üèÜ Ranking de {tipo_localidade}s por percentual m√©dio:**")
        
        # Dividir em grupos
        total = len(df_medias)
        tercil_size = total // 3
        
        # Primeiro tercil (melhores)
        top_tercil = df_medias.head(tercil_size)
        st.markdown("**ü•á Primeiro tercil (maiores percentuais):**")
        for i, row in top_tercil.iterrows():
            st.write(f"‚Ä¢ {row['Estado']}: {row['Media']:.1f}% (¬±{row['Desvio']:.1f}%)")
        
        # √öltimo tercil (menores)
        bottom_tercil = df_medias.tail(tercil_size)
        st.markdown("**ü•â √öltimo tercil (menores percentuais):**")
        for i, row in bottom_tercil.iterrows():
            st.write(f"‚Ä¢ {row['Estado']}: {row['Media']:.1f}% (¬±{row['Desvio']:.1f}%)")
        
        # An√°lise de disparidades
        st.markdown("**‚öñÔ∏è An√°lise de disparidades:**")
        
        maior_media = df_medias['Media'].max()
        menor_media = df_medias['Media'].min()
        razao_disparidade = maior_media / menor_media if menor_media > 0 else 0
        
        st.write(f"‚Ä¢ **Raz√£o de disparidade:** {razao_disparidade:.2f}x")
        st.write(f"‚Ä¢ **Diferen√ßa absoluta:** {maior_media - menor_media:.1f} pontos percentuais")
        
        # Classifica√ß√£o da disparidade
        if razao_disparidade < 1.5:
            nivel_disparidade = "baixa"
        elif razao_disparidade < 2.5:
            nivel_disparidade = "moderada"
        else:
            nivel_disparidade = "alta"
        
        st.write(f"‚Ä¢ **N√≠vel de disparidade:** {nivel_disparidade}")
        
    except Exception as e:
        st.error(f"Erro ao gerar ranking: {str(e)}")


def _mostrar_insights_padroes(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra insights e padr√µes identificados nos dados.
    """
    try:
        st.markdown("**üîç An√°lise de padr√µes regionais:**")
        
        # An√°lise por regi√£o (se for por estado)
        if tipo_localidade.lower() == "estado":
            df_com_regiao = _adicionar_regiao_aos_estados(df_dados)
            
            if 'Regiao' in df_com_regiao.columns:
                analise_regional = df_com_regiao.groupby('Regiao')['Percentual'].agg(['mean', 'std']).reset_index()
                analise_regional.columns = ['Regiao', 'Media', 'Desvio']
                analise_regional = analise_regional.sort_values('Media', ascending=False)
                
                st.markdown("**üìç Padr√µes por regi√£o:**")
                for i, row in analise_regional.iterrows():
                    st.write(f"‚Ä¢ **{row['Regiao']}:** {row['Media']:.1f}% (¬±{row['Desvio']:.1f}%)")
                
                # Identificar regi√£o com maior variabilidade
                regiao_mais_variavel = analise_regional.loc[analise_regional['Desvio'].idxmax()]
                st.write(f"‚Ä¢ **Regi√£o com maior variabilidade interna:** {regiao_mais_variavel['Regiao']}")
        
        # An√°lise de distribui√ß√£o
        st.markdown("**üìä Caracter√≠sticas da distribui√ß√£o:**")
        
        # Teste de normalidade simplificado
        percentuais = df_dados['Percentual'].values
        media = percentuais.mean()
        mediana = np.median(percentuais)
        
        if abs(media - mediana) < 1:
            distribuicao = "sim√©trica"
        elif media > mediana:
            distribuicao = "assim√©trica √† direita"
        else:
            distribuicao = "assim√©trica √† esquerda"
        
        st.write(f"‚Ä¢ **Formato da distribui√ß√£o:** {distribuicao}")
        
        # Concentra√ß√£o
        q1 = np.percentile(percentuais, 25)
        q3 = np.percentile(percentuais, 75)
        iqr = q3 - q1
        
        st.write(f"‚Ä¢ **Amplitude interquartil:** {iqr:.1f}%")
        
        # Outliers
        limite_superior = q3 + 1.5 * iqr
        limite_inferior = q1 - 1.5 * iqr
        
        outliers = df_dados[(df_dados['Percentual'] > limite_superior) | 
                           (df_dados['Percentual'] < limite_inferior)]
        
        if len(outliers) > 0:
            st.write(f"‚Ä¢ **Valores at√≠picos identificados:** {len(outliers)}")
            st.markdown("**üö® Casos at√≠picos:**")
            for i, row in outliers.iterrows():
                st.write(f"  - {row['Estado']} ({row['Categoria']}): {row['Percentual']:.1f}%")
        else:
            st.write("‚Ä¢ **Valores at√≠picos:** Nenhum identificado")
        
    except Exception as e:
        st.error(f"Erro ao gerar insights: {str(e)}")


def _mostrar_tabela_interativa(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra tabela interativa com filtros e formata√ß√£o.
    """
    try:
        # Filtros interativos
        col1, col2 = st.columns(2)
        
        with col1:
            # Filtro por categoria
            categorias = ['Todas'] + sorted(df_dados['Categoria'].unique().tolist())
            categoria_filtro = st.selectbox(
                "Filtrar por categoria:",
                categorias,
                key="filtro_categoria_tabela"
            )
        
        with col2:
            # Filtro por faixa de percentual
            min_val = float(df_dados['Percentual'].min())
            max_val = float(df_dados['Percentual'].max())
            
            faixa_percentual = st.slider(
                "Faixa de percentual:",
                min_value=min_val,
                max_value=max_val,
                value=(min_val, max_val),
                step=0.1,
                key="filtro_percentual_tabela"
            )
        
        # Aplicar filtros
        df_filtrado = df_dados.copy()
        
        if categoria_filtro != 'Todas':
            df_filtrado = df_filtrado[df_filtrado['Categoria'] == categoria_filtro]
        
        df_filtrado = df_filtrado[
            (df_filtrado['Percentual'] >= faixa_percentual[0]) & 
            (df_filtrado['Percentual'] <= faixa_percentual[1])
        ]
        
        # Ordena√ß√£o
        ordenacao = st.radio(
            "Ordenar por:",
            ["Estado", "Categoria", "Percentual (crescente)", "Percentual (decrescente)"],
            horizontal=True,
            key="ordenacao_tabela"
        )
        
        if ordenacao == "Estado":
            df_filtrado = df_filtrado.sort_values('Estado')
        elif ordenacao == "Categoria":
            df_filtrado = df_filtrado.sort_values('Categoria')
        elif ordenacao == "Percentual (crescente)":
            df_filtrado = df_filtrado.sort_values('Percentual')
        else:
            df_filtrado = df_filtrado.sort_values('Percentual', ascending=False)
        
        # Exibir tabela
        st.dataframe(
            df_filtrado,
            column_config={
                'Estado': st.column_config.TextColumn(
                    tipo_localidade.capitalize(),
                    help=f"Nome do {tipo_localidade}"
                ),
                'Categoria': st.column_config.TextColumn(
                    "Categoria",
                    help="Categoria do aspecto social"
                ),
                'Percentual': st.column_config.NumberColumn(
                    "Percentual",
                    help="Percentual de candidatos nesta categoria",
                    format="%.1f%%"
                )
            },
            height=400,
            use_container_width=True
        )
        
        # Estat√≠sticas da tabela filtrada
        if len(df_filtrado) > 0:
            st.caption(f"üìä Exibindo {len(df_filtrado)} registros de {len(df_dados)} totais")
        else:
            st.warning("Nenhum registro encontrado com os filtros aplicados.")
        
    except Exception as e:
        st.error(f"Erro ao gerar tabela interativa: {str(e)}")


def _mostrar_opcoes_download(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra op√ß√µes de download e exporta√ß√£o.
    """
    try:
        st.markdown("**üíæ Op√ß√µes de download:**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Download da tabela completa
            csv_completo = df_dados.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üìÑ Baixar dados completos (CSV)",
                data=csv_completo,
                file_name=f"aspectos_sociais_{tipo_localidade}_completo.csv",
                mime="text/csv",
                key="download_completo"
            )
        
        with col2:
            # Download da tabela piv√¥
            try:
                df_pivot = _criar_tabela_pivot(df_dados, tipo_localidade)
                if df_pivot is not None and not df_pivot.empty:
                    csv_pivot = df_pivot.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="üìä Baixar tabela cruzada (CSV)",
                        data=csv_pivot,
                        file_name=f"aspectos_sociais_{tipo_localidade}_pivot.csv",
                        mime="text/csv",
                        key="download_pivot"
                    )
            except Exception:
                st.info("Tabela cruzada n√£o dispon√≠vel para download")
        
        # Informa√ß√µes sobre os dados
        st.markdown("**‚ÑπÔ∏è Informa√ß√µes sobre os dados:**")
        st.write(f"‚Ä¢ **Total de registros:** {len(df_dados)}")
        st.write(f"‚Ä¢ **{tipo_localidade.capitalize()}s √∫nicos:** {df_dados['Estado'].nunique()}")
        st.write(f"‚Ä¢ **Categorias √∫nicas:** {df_dados['Categoria'].nunique()}")
        st.write(f"‚Ä¢ **Per√≠odo de coleta:** ENEM 2023")
        
    except Exception as e:
        st.error(f"Erro ao gerar op√ß√µes de download: {str(e)}")


def _mostrar_tabela_basica(df_dados: pd.DataFrame, tipo_localidade: str) -> None:
    """
    Mostra vers√£o b√°sica da tabela (fallback).
    """
    try:
        st.markdown("**üìã Tabela b√°sica de dados:**")
        
        # Criar tabela piv√¥ simples
        df_pivot = _criar_tabela_pivot(df_dados, tipo_localidade)
        
        if df_pivot is not None and not df_pivot.empty:
            st.dataframe(
                df_pivot,
                column_config={
                    col: st.column_config.NumberColumn(col, format="%.1f%%") 
                    for col in df_pivot.columns if col != tipo_localidade.capitalize()
                },
                height=400
            )
        else:
            # Fallback para tabela simples
            st.dataframe(df_dados, height=400)
        
    except Exception as e:
        st.error(f"Erro ao exibir tabela b√°sica: {str(e)}")


# Fun√ß√µes auxiliares para an√°lise de correla√ß√£o

def _mostrar_resumo_associacao(
    metricas: Dict[str, Any], 
    variaveis_sociais: Dict[str, Dict[str, Any]], 
    var_x: str, 
    var_y: str
) -> None:
    """
    Mostra resumo da associa√ß√£o entre vari√°veis.
    """
    st.write("#### Resumo da associa√ß√£o:")
    
    # Verificar se temos m√©tricas v√°lidas
    if 'interpretacao' not in metricas or 'coeficiente' not in metricas:
        st.warning("Dados insuficientes para an√°lise de associa√ß√£o.")
        return
    
    # Mostrar for√ßa da associa√ß√£o
    st.write(f"‚Ä¢ **For√ßa da associa√ß√£o:** {metricas['interpretacao']}")
    st.write(f"‚Ä¢ **Coeficiente de conting√™ncia:** {metricas['coeficiente']:.4f}")
    
    # Mostrar signific√¢ncia estat√≠stica
    if metricas.get('significativo', False):
        st.write("‚Ä¢ **Signific√¢ncia estat√≠stica:** H√° evid√™ncia de associa√ß√£o significativa")
        st.write(f"‚Ä¢ **Valor p:** {metricas.get('valor_p', 0):.5f} (significativo)")
    else:
        st.write("‚Ä¢ **Signific√¢ncia estat√≠stica:** Sem evid√™ncia de associa√ß√£o significativa")
        st.write(f"‚Ä¢ **Valor p:** {metricas.get('valor_p', 1):.5f} (n√£o significativo)")
    
    # Mostrar tamanho do efeito
    if 'tamanho_efeito' in metricas and metricas['tamanho_efeito'] != 'indefinido':
        st.write(f"‚Ä¢ **Tamanho do efeito:** {metricas['tamanho_efeito']}")


def _mostrar_metricas_estatisticas(metricas: Dict[str, Any]) -> None:
    """
    Mostra m√©tricas estat√≠sticas detalhadas.
    """
    st.write("#### M√©tricas estat√≠sticas:")
    
    # Verificar se temos m√©tricas v√°lidas
    if 'qui_quadrado' not in metricas or 'v_cramer' not in metricas:
        st.warning("Dados insuficientes para m√©tricas estat√≠sticas detalhadas.")
        return
    
    # Qui-quadrado e graus de liberdade
    st.write(f"‚Ä¢ **Estat√≠stica qui-quadrado:** {metricas['qui_quadrado']:.2f}")
    st.write(f"‚Ä¢ **Graus de liberdade:** {metricas.get('gl', 0)}")
    
    # V de Cramer
    st.write(f"‚Ä¢ **V de Cramer:** {metricas['v_cramer']:.4f}")
    
    # Informa√ß√£o m√∫tua
    if 'info_mutua_norm' in metricas:
        st.write(f"‚Ä¢ **Informa√ß√£o m√∫tua normalizada:** {metricas['info_mutua_norm']:.4f}")
    
    # Tamanho da amostra
    if 'n_amostras' in metricas:
        st.write(f"‚Ä¢ **Tamanho da amostra:** {metricas['n_amostras']:,}")


def _mostrar_analise_categorias(
    df_correlacao: pd.DataFrame, 
    var_x_plot: str, 
    var_y_plot: str, 
    variaveis_sociais: Dict[str, Dict[str, Any]], 
    var_x: str, 
    var_y: str
) -> None:
    """
    Mostra an√°lise detalhada das combina√ß√µes de categorias.
    """
    # Verificar se temos dados v√°lidos
    if df_correlacao is None or df_correlacao.empty:
        st.warning("Dados insuficientes para an√°lise de categorias.")
        return
    
    if var_x_plot not in df_correlacao.columns or var_y_plot not in df_correlacao.columns:
        st.warning("Vari√°veis n√£o encontradas nos dados.")
        return
    
    try:
        st.write("#### An√°lise das combina√ß√µes de categorias:")
        
        # Criar tabela de conting√™ncia
        tabela_contingencia = pd.crosstab(
            df_correlacao[var_x_plot], 
            df_correlacao[var_y_plot],
            margins=True
        )
        
        st.write("**Tabela de conting√™ncia:**")
        st.dataframe(tabela_contingencia, use_container_width=True)
        
        # Mostrar percentuais
        tabela_percentuais = pd.crosstab(
            df_correlacao[var_x_plot], 
            df_correlacao[var_y_plot], 
            normalize='index'
        ) * 100
        
        st.write("**Percentuais por linha:**")
        st.dataframe(tabela_percentuais.round(1), use_container_width=True)
        
    except Exception as e:
        st.error(f"Erro ao gerar an√°lise de categorias: {str(e)}")


def _mostrar_estatisticas_principais_distribuicao(
    estatisticas: Dict[str, Any], 
    nome_aspecto: str
) -> None:
    """
    Mostra estat√≠sticas principais da distribui√ß√£o.
    """
    st.write(f"### Estat√≠sticas de {nome_aspecto}")
    
    # Verificar se temos estat√≠sticas v√°lidas
    if estatisticas is None or 'total' not in estatisticas:
        st.warning("Dados insuficientes para estat√≠sticas de distribui√ß√£o.")
        return
    
    # Total de candidatos
    st.write(f"**Total de candidatos:** {estatisticas['total']:,}")
    
    # Categoria mais frequente
    if estatisticas.get('categoria_mais_frequente') is not None:
        mais_freq = estatisticas['categoria_mais_frequente']
        st.write(f"**Categoria mais frequente:** {mais_freq['Categoria']} ({mais_freq['Quantidade']:,} candidatos)")
    
    # Categoria menos frequente
    if estatisticas.get('categoria_menos_frequente') is not None:
        menos_freq = estatisticas['categoria_menos_frequente']
        st.write(f"**Categoria menos frequente:** {menos_freq['Categoria']} ({menos_freq['Quantidade']:,} candidatos)")
    
    # N√∫mero de categorias
    st.write(f"**N√∫mero de categorias:** {estatisticas.get('num_categorias', 0)}")
    
    # M√©dia e mediana
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**M√©dia:** {estatisticas.get('media', 0):,.1f}")
    with col2:
        st.write(f"**Mediana:** {estatisticas.get('mediana', 0):,.1f}")


def _mostrar_analise_concentracao_equidade(
    estatisticas: Dict[str, Any], 
    nome_aspecto: str
) -> None:
    """
    Mostra an√°lise de concentra√ß√£o e equidade.
    """
    st.write("### An√°lise de distribui√ß√£o")
    
    # Verificar se temos estat√≠sticas v√°lidas
    if estatisticas is None or 'indice_concentracao' not in estatisticas:
        st.warning("Dados insuficientes para an√°lise de concentra√ß√£o.")
        return
    
    # √çndice de concentra√ß√£o
    indice = estatisticas['indice_concentracao']
    st.write(f"**√çndice de concentra√ß√£o:** {indice:.4f}")
    st.write(f"**Classifica√ß√£o:** {estatisticas.get('classificacao_concentracao', 'N√£o dispon√≠vel')}")
    
    # Raz√£o entre maior e menor categoria
    if (estatisticas.get('categoria_mais_frequente') is not None and 
        estatisticas.get('categoria_menos_frequente') is not None):
        razao = estatisticas.get('razao_max_min', 0)
        st.write(f"**Raz√£o maior/menor:** {razao:.2f}x")
    
    # Coeficiente de varia√ß√£o
    if 'coef_variacao' in estatisticas:
        cv = estatisticas['coef_variacao']
        st.write(f"**Coeficiente de varia√ß√£o:** {cv:.1f}%")


def _mostrar_analise_concentracao_percentual(contagem_aspecto: pd.DataFrame) -> None:
    """
    Mostra an√°lise de concentra√ß√£o por percentual acumulado.
    """
    # Verificar se temos dados v√°lidos
    if contagem_aspecto is None or contagem_aspecto.empty:
        st.warning("Dados insuficientes para an√°lise de concentra√ß√£o percentual.")
        return
    
    if 'Percentual' not in contagem_aspecto.columns:
        st.warning("Coluna 'Percentual' n√£o encontrada nos dados.")
        return
        
    try:
        st.write("### An√°lise de concentra√ß√£o")
        
        # Ordenar por percentual decrescente
        df_ordenado = contagem_aspecto.sort_values('Percentual', ascending=False)
        
        # Calcular percentual acumulado
        df_ordenado['Percentual_Acumulado'] = df_ordenado['Percentual'].cumsum()
        
        # Mostrar os top 3
        st.write("**Top 3 categorias (percentual acumulado):**")
        top_3 = df_ordenado.head(3)
        for i, row in top_3.iterrows():
            st.write(f"‚Ä¢ {row['Categoria']}: {row['Percentual']:.1f}% (acumulado: {row['Percentual_Acumulado']:.1f}%)")
        
    except Exception as e:
        st.error(f"Erro ao gerar an√°lise de concentra√ß√£o percentual: {str(e)}")


def _configurar_titulo_analise_regional(
    df_dados: pd.DataFrame, 
    aspecto_social: str, 
    categoria_selecionada: str, 
    nome_aspecto: str, 
    tipo_localidade: str
) -> None:
    """
    Configura t√≠tulo e seletores para an√°lise regional.
    """
    # Obter lista de categorias dispon√≠veis
    categorias_disponiveis = sorted(df_dados['Categoria'].unique())
    
    st.write(f"### An√°lise de {nome_aspecto} por {tipo_localidade}")
    
    # Op√ß√£o para selecionar categoria diferente
    if len(categorias_disponiveis) > 1:
        st.selectbox(
            "Categoria em an√°lise:",
            categorias_disponiveis,
            index=categorias_disponiveis.index(categoria_selecionada) if categoria_selecionada in categorias_disponiveis else 0,
            key="categoria_analise_regional"
        )
    else:
        st.write(f"**Categoria em an√°lise:** {categoria_selecionada}")


def _mostrar_estatisticas_regionais(
    analise: Dict[str, Any], 
    categoria_selecionada: str, 
    tipo_localidade: str
) -> None:
    """
    Mostra estat√≠sticas gerais da an√°lise regional.
    """
    st.write(f"#### Estat√≠sticas da categoria '{categoria_selecionada}'")
    
    # Verificar se temos an√°lise v√°lida
    if analise is None or 'percentual_medio' not in analise:
        st.warning("Dados insuficientes para an√°lise regional.")
        return
    
    # Estat√≠sticas principais em colunas
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Percentual m√©dio", f"{analise['percentual_medio']:.1f}%")
    
    with col2:
        st.metric("Desvio padr√£o", f"{analise['desvio_padrao']:.1f}%")
    
    with col3:
        st.metric("Coef. varia√ß√£o", f"{analise['coef_variacao']:.1f}%")
    
    # Verificar estados com valores extremos
    _mostrar_localidades_extremas(analise, tipo_localidade)


def _mostrar_localidades_extremas(
    analise: Dict[str, Any], 
    tipo_localidade: str
) -> None:
    """
    Mostra localidades com valores extremos.
    """
    # Verificar se temos dados de valores extremos
    if analise.get('maior_percentual') is None or analise.get('menor_percentual') is None:
        return
    
    # Formatar nome da localidade
    nome_loc = tipo_localidade.capitalize()
    
    st.write(f"#### {nome_loc}s com valores extremos:")
    
    # Maior percentual
    maior = analise['maior_percentual']
    if isinstance(maior, pd.Series) and 'Estado' in maior.index and 'Percentual' in maior.index:
        st.write(f"‚Ä¢ **Maior percentual:** {maior['Estado']} ({maior['Percentual']:.1f}%)")
    
    # Menor percentual
    menor = analise['menor_percentual']
    if isinstance(menor, pd.Series) and 'Estado' in menor.index and 'Percentual' in menor.index:
        st.write(f"‚Ä¢ **Menor percentual:** {menor['Estado']} ({menor['Percentual']:.1f}%)")
    
    # Calcular diferen√ßa entre maior e menor (se ambos dispon√≠veis)
    if (isinstance(maior, pd.Series) and isinstance(menor, pd.Series) and 
        'Percentual' in maior.index and 'Percentual' in menor.index):
        diferenca = maior['Percentual'] - menor['Percentual']
        st.write(f"‚Ä¢ **Diferen√ßa:** {diferenca:.1f} pontos percentuais")


def _mostrar_variabilidade_regional(
    analise: Dict[str, Any], 
    nome_aspecto: str, 
    categoria_selecionada: str
) -> None:
    """
    Mostra an√°lise de variabilidade regional.
    """
    st.write("#### An√°lise de variabilidade regional:")
    
    # Verificar se temos dados para an√°lise
    if analise is None or 'coef_variacao' not in analise:
        st.warning("Dados insuficientes para an√°lise de variabilidade.")
        return
    
    # Exibir classifica√ß√£o de variabilidade
    st.write(f"**N√≠vel de variabilidade:** {analise.get('variabilidade', 'N√£o dispon√≠vel')}")
    
    # Interpretar disparidade
    st.write(f"**N√≠vel de disparidade regional:** {analise.get('disparidade', 'Indefinida')}")
    
    # Informa√ß√£o sobre √≠ndice de Gini
    if 'indice_gini' in analise:
        st.write(f"**√çndice de Gini:** {analise['indice_gini']:.4f}")


def _mostrar_ranking_localidades(
    df_dados: pd.DataFrame, 
    categoria_selecionada: str, 
    analise: Dict[str, Any], 
    tipo_localidade: str
) -> None:
    """
    Mostra ranking completo de localidades.
    """
    st.write(f"#### Ranking de {tipo_localidade}s:")
    
    # Verificar se temos dados v√°lidos
    if df_dados is None or df_dados.empty:
        st.warning("Dados insuficientes para ranking.")
        return
    
    try:
        # Filtrar pela categoria selecionada
        df_categoria = df_dados[df_dados['Categoria'] == categoria_selecionada]
        
        # Ordenar por percentual decrescente
        df_ranking = df_categoria.sort_values('Percentual', ascending=False)
        
        # Mostrar top 10
        st.write("**Top 10:**")
        top_10 = df_ranking.head(10)
        for i, row in top_10.iterrows():
            st.write(f"{i+1}. {row['Estado']}: {row['Percentual']:.1f}%")
        
    except Exception as e:
        st.error(f"Erro ao gerar ranking: {str(e)}")


def _mostrar_analise_por_regiao(
    df_dados: pd.DataFrame, 
    categoria_selecionada: str, 
    nome_aspecto: str
) -> None:
    """
    Mostra an√°lise agrupada por regi√£o.
    """
    # Verificar se temos dados v√°lidos
    if df_dados is None or df_dados.empty:
        st.warning("Dados insuficientes para an√°lise por regi√£o.")
        return
    
    try:
        st.write("#### An√°lise por regi√£o:")
        
        # Adicionar informa√ß√£o de regi√£o
        df_com_regiao = _adicionar_regiao_aos_estados(df_dados)
        
        if 'Regi√£o' not in df_com_regiao.columns:
            st.warning("Informa√ß√£o de regi√£o n√£o dispon√≠vel.")
            return
        
        # Filtrar pela categoria selecionada
        df_categoria = df_com_regiao[df_com_regiao['Categoria'] == categoria_selecionada]
        
        # Agrupar por regi√£o
        analise_regional = df_categoria.groupby('Regi√£o')['Percentual'].agg(['mean', 'std', 'count']).reset_index()
        analise_regional.columns = ['Regi√£o', 'M√©dia', 'Desvio', 'Estados']
        analise_regional = analise_regional.sort_values('M√©dia', ascending=False)
        
        # Mostrar resultados
        for i, row in analise_regional.iterrows():
            st.write(f"‚Ä¢ **{row['Regi√£o']}:** {row['M√©dia']:.1f}% (¬±{row['Desvio']:.1f}%, {row['Estados']} estados)")
        
    except Exception as e:
        st.error(f"Erro ao gerar an√°lise por regi√£o: {str(e)}")


def _criar_tabela_pivot(
    df_dados: pd.DataFrame, 
    tipo_localidade: str
) -> pd.DataFrame:
    """
    Cria tabela piv√¥ para visualiza√ß√£o completa dos dados.
    
    Par√¢metros:
    -----------
    df_dados : DataFrame
        DataFrame com os dados brutos
    tipo_localidade : str
        Tipo de localidade (estado ou regi√£o)
        
    Retorna:
    --------
    DataFrame
        Tabela piv√¥ formatada
    """
    try:
        # Verificar se temos dados v√°lidos
        if df_dados is None or df_dados.empty:
            return pd.DataFrame()
        
        # Usar pivot_table em vez de pivot para lidar com valores duplicados
        df_pivot = df_dados.pivot_table(
            index='Estado', 
            columns='Categoria', 
            values='Percentual',
            aggfunc='mean'  # Calcula a m√©dia quando h√° valores duplicados
        ).reset_index()
        
        # Renomear o √≠ndice para o tipo de localidade
        df_pivot = df_pivot.rename(columns={'Estado': tipo_localidade.capitalize()})
        
        # Expandir colunas para formato adequado
        df_pivot = df_pivot.round(1)
        
        return df_pivot
    
    except Exception as e:
        print(f"Erro ao criar tabela piv√¥: {e}")
        return pd.DataFrame()


def _adicionar_regiao_aos_estados(df: pd.DataFrame) -> pd.DataFrame:
    """
    Adiciona a informa√ß√£o de regi√£o para cada estado.
    
    Par√¢metros:
    -----------
    df : DataFrame
        DataFrame com coluna 'Estado'
        
    Retorna:
    --------
    DataFrame
        DataFrame com coluna 'Regi√£o' adicionada
    """
    # Verificar se temos dados v√°lidos
    if df is None or df.empty or 'Estado' not in df.columns:
        return df
    
    try:
        # Criar c√≥pia para n√£o modificar o original
        df_com_regiao = df.copy()
        
        # Obter mapeamento de regi√µes
        regioes_mapping = mappings.get('regioes_mapping', {})
        
        # Criar mapeamento invertido (de estado para regi√£o)
        estado_para_regiao = {}
        for regiao, estados in regioes_mapping.items():
            for estado in estados:
                estado_para_regiao[estado] = regiao
        
        # Adicionar coluna de regi√£o
        df_com_regiao['Regi√£o'] = df_com_regiao['Estado'].map(estado_para_regiao)
        
        return df_com_regiao
    
    except Exception as e:
        print(f"Erro ao adicionar regi√£o aos estados: {e}")
        return df