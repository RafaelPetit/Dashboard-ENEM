{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_localizacao = [\n",
    "    # Localização\n",
    "    'SG_UF_PROVA',\n",
    "    'SG_REGIAO',\n",
    "]\n",
    "\n",
    "colunas_dashboard = [\n",
    "    'SG_UF_PROVA',\n",
    "    'SG_REGIAO',\n",
    "    \n",
    "    # Notas\n",
    "    'NU_NOTA_CN', \n",
    "    'NU_NOTA_CH', \n",
    "    'NU_NOTA_LC', \n",
    "    'NU_NOTA_MT',\n",
    "    'NU_NOTA_REDACAO',\n",
    "]\n",
    "\n",
    "colunas_geral = [\n",
    "    'SG_UF_PROVA',\n",
    "    'SG_REGIAO',\n",
    "\n",
    "    # Presença\n",
    "    'TP_PRESENCA_CN', \n",
    "    'TP_PRESENCA_CH', \n",
    "    'TP_PRESENCA_LC', \n",
    "    'TP_PRESENCA_MT',\n",
    "    'TP_PRESENCA_GERAL',\n",
    "    'TP_PRESENCA_REDACAO',\n",
    "\n",
    "    # Notas\n",
    "    'NU_NOTA_CN', \n",
    "    'NU_NOTA_CH', \n",
    "    'NU_NOTA_LC', \n",
    "    'NU_NOTA_MT',\n",
    "    'NU_NOTA_REDACAO'\n",
    "    ]\n",
    "\n",
    "colunas_aspectos_sociais = [\n",
    "    'SG_UF_PROVA',\n",
    "    'SG_REGIAO',\n",
    "\n",
    "    # Variáveis sociais\n",
    "    'TP_SEXO',\n",
    "    'TP_COR_RACA',\n",
    "    'TP_ESTADO_CIVIL',\n",
    "    'TP_FAIXA_ETARIA',\n",
    "    'TP_ST_CONCLUSAO',\n",
    "    'TP_DEPENDENCIA_ADM_ESC',\n",
    "    'TP_ESCOLA',\n",
    "    'TP_ENSINO',\n",
    "    'TP_LOCALIZACAO_ESC',\n",
    "    \n",
    "    \n",
    "    # Questões socioeconômicas\n",
    "    'Q001', \n",
    "    'Q002', \n",
    "    'Q005', \n",
    "    'TP_FAIXA_SALARIAL', \n",
    "    'Q025',\n",
    "    \n",
    "    # Infraestrutura\n",
    "    'NU_INFRAESTRUTURA'\n",
    "    ]\n",
    "\n",
    "colunas_desempenho = [\n",
    "    'SG_UF_PROVA',\n",
    "    'SG_REGIAO',\n",
    "    \n",
    "    # Características do candidato\n",
    "    'TP_SEXO',\n",
    "    'TP_COR_RACA',\n",
    "    'TP_DEPENDENCIA_ADM_ESC',\n",
    "    'TP_ST_CONCLUSAO',\n",
    "    'TP_FAIXA_ETARIA',\n",
    "    'TP_ESTADO_CIVIL',\n",
    "    'TP_ESCOLA',\n",
    "    'TP_ENSINO',\n",
    "    'TP_LOCALIZACAO_ESC',\n",
    "    'NU_INFRAESTRUTURA',\n",
    "    \n",
    "    # Notas\n",
    "    'NU_NOTA_CN', \n",
    "    'NU_NOTA_CH', \n",
    "    'NU_NOTA_LC', \n",
    "    'NU_NOTA_MT',\n",
    "    'NU_NOTA_REDACAO',\n",
    "    \n",
    "    # Categorias de desempenho\n",
    "    'NU_DESEMPENHO',\n",
    "\n",
    "    # Questões socioeconômicas\n",
    "    'Q001',\n",
    "    'Q002',\n",
    "    'Q005',\n",
    "    'TP_FAIXA_SALARIAL',\n",
    "    'Q025'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar microdados completos\n",
    "arquivo = '../../Iniciação Científica/Códigos/microdados_tratado.parquet'\n",
    "arquivo_dtypes = '../../Iniciação Científica/Códigos/dtypes.json'\n",
    "\n",
    "# Especificar explicitamente o engine\n",
    "microdados = pd.read_parquet(arquivo, engine='pyarrow')\n",
    "\n",
    "dtypes = pd.read_json(arquivo_dtypes, orient='index', typ='series')\n",
    "\n",
    "microdados = microdados.astype(dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "microdados = microdados[microdados['SG_REGIAO'].isin(['Norte', 'Nordeste'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas desempenho sem notas zeros e range de começando de 100\n",
    "microdados_desempenho = microdados.copy()\n",
    "\n",
    "microdados_desempenho = microdados_desempenho[(microdados_desempenho['TP_PRESENCA_GERAL'] == 3) & (microdados_desempenho['NU_MEDIA_GERAL'] != -1)]\n",
    "\n",
    "microdados_desempenho = microdados_desempenho[microdados_desempenho['NU_MEDIA_GERAL'] != -1]\n",
    "\n",
    "# Filtrar onde todas as notas são >= 100\n",
    "colunas_notas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'NU_MEDIA_GERAL']\n",
    "condicao = True\n",
    "for col in colunas_notas:\n",
    "    condicao = condicao & (microdados_desempenho[col] >= 100)\n",
    "\n",
    "microdados_desempenho = microdados_desempenho[condicao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar arquivos separados para cada aba\n",
    "microdados[colunas_localizacao].to_parquet('sample_localizacao.parquet', index=False, engine='pyarrow')\n",
    "microdados[colunas_geral].to_parquet('sample_geral.parquet', index=False, engine='pyarrow')\n",
    "microdados[colunas_aspectos_sociais].to_parquet('sample_aspectos_sociais.parquet', index=False, engine='pyarrow')\n",
    "microdados_desempenho[colunas_desempenho].to_parquet('sample_desempenho.parquet', index=False, engine='pyarrow')\n",
    "\n",
    "# Criar arquivos dtypes separados\n",
    "dtypes_localizacao = {col: str(microdados[col].dtype) for col in colunas_localizacao if col in microdados.columns}\n",
    "dtypes_geral = {col: str(microdados[col].dtype) for col in colunas_geral if col in microdados.columns}\n",
    "dtypes_aspectos = {col: str(microdados[col].dtype) for col in colunas_aspectos_sociais if col in microdados.columns}\n",
    "dtypes_desempenho = {col: str(microdados[col].dtype) for col in colunas_desempenho if col in microdados.columns}\n",
    "\n",
    "# Usar json module em vez do pandas to_json para evitar problemas de serialização\n",
    "# Salva o mapeamento em um arquivo JSON\n",
    "\n",
    "with open('dtypes_localizacao.json', 'w') as f:\n",
    "    json.dump(dtypes_localizacao, f)\n",
    "with open('dtypes_geral.json', 'w') as f:\n",
    "    json.dump(dtypes_geral, f)\n",
    "with open('dtypes_aspectos_sociais.json', 'w') as f:\n",
    "    json.dump(dtypes_aspectos, f)\n",
    "with open('dtypes_desempenho.json', 'w') as f:\n",
    "    json.dump(dtypes_desempenho, f)\n",
    "with open('dtypes.json', 'w') as f:\n",
    "    json.dump(dtypes.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas no DataFrame mas não estavam na lista: {'NU_MEDIA_GERAL'}\n",
      "Colunas da lista não presentes no DataFrame: set()\n"
     ]
    }
   ],
   "source": [
    "todas_colunas = (\n",
    "    colunas_localizacao +\n",
    "    colunas_dashboard +\n",
    "    colunas_geral +\n",
    "    colunas_aspectos_sociais +\n",
    "    colunas_desempenho\n",
    ")\n",
    "\n",
    "# Remove colunas duplicadas\n",
    "colunas_unicas = set(todas_colunas)\n",
    "\n",
    "# Colunas que estão no df mas não estavam nas suas listas:\n",
    "faltantes = set(microdados.columns) - colunas_unicas\n",
    "print(\"Colunas no DataFrame mas não estavam na lista:\", faltantes)\n",
    "\n",
    "# E colunas que você listou mas não existem no DataFrame:\n",
    "nao_presentes = colunas_unicas - set(microdados.    columns)\n",
    "print(\"Colunas da lista não presentes no DataFrame:\", nao_presentes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_INFRAESTRUTURA\n",
       "2    469564\n",
       "3    468782\n",
       "1    273864\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdados_desempenho['NU_INFRAESTRUTURA'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
