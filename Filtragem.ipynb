{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_gerenicas = [\n",
    " # Localização\n",
    "    'SG_UF_PROVA',\n",
    "    # Notas\n",
    "    'NU_NOTA_CN', \n",
    "    'NU_NOTA_CH', \n",
    "    'NU_NOTA_LC', \n",
    "    'NU_NOTA_MT',\n",
    "    'NU_NOTA_REDACAO',\n",
    "\n",
    "    # Questões socioeconômicas\n",
    "    'Q001', \n",
    "    'Q002', \n",
    "    'Q005', \n",
    "    'Q006', \n",
    "    'Q025',\n",
    "    'TP_FAIXA_SALARIAL',\n",
    "\n",
    "     # Características do candidato\n",
    "    'TP_SEXO',\n",
    "    'TP_COR_RACA',\n",
    "    'TP_DEPENDENCIA_ADM_ESC',\n",
    "    'TP_ST_CONCLUSAO',\n",
    "    'TP_FAIXA_ETARIA',\n",
    "]\n",
    "\n",
    "colunas_geral = [\n",
    "    # Presença\n",
    "    'TP_PRESENCA_CN', \n",
    "    'TP_PRESENCA_CH', \n",
    "    'TP_PRESENCA_LC', \n",
    "    'TP_PRESENCA_MT',\n",
    "    'TP_PRESENCA_GERAL',\n",
    "    'TP_PRESENCA_REDACAO',\n",
    "]\n",
    "\n",
    "colunas_aspectos_sociais = [\n",
    "    # Variáveis sociais\n",
    "    'TP_ESTADO_CIVIL',\n",
    "    'TP_LOCALIZACAO_ESC',\n",
    "\n",
    "    # Infraestrutura\n",
    "    'NU_INFRAESTRUTURA',\n",
    "]\n",
    "\n",
    "colunas_desempenho = [\n",
    "    # Categorias de desempenho\n",
    "    'NU_DESEMPENHO',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar microdados completos\n",
    "arquivo = '../Iniciação Científica/Códigos/microdados_tratado.parquet'\n",
    "\n",
    "# Especificar explicitamente o engine\n",
    "microdados = pd.read_parquet(arquivo, engine='pyarrow')\n",
    "\n",
    "microdados = microdados.sample(1500000, random_state=42)\n",
    "\n",
    "# Adicionar os dtypes pre definidos - usando try/except para evitar erros\n",
    "try:\n",
    "    dtypes = pd.read_json(\"dtypes.json\", typ='series')\n",
    "    microdados = microdados.astype(dtypes.to_dict())\n",
    "except Exception as e:\n",
    "    print(f\"Aviso ao aplicar dtypes: {e}\")\n",
    "    # Continuar com os tipos atuais\n",
    "\n",
    "# Criar arquivos separados para cada aba\n",
    "microdados[colunas_gerenicas].to_parquet('sample_gerenico.parquet', index=False, engine='pyarrow')\n",
    "microdados[colunas_geral].to_parquet('sample_geral.parquet', index=False, engine='pyarrow')\n",
    "microdados[colunas_aspectos_sociais].to_parquet('sample_aspectos_sociais.parquet', index=False, engine='pyarrow')\n",
    "microdados[colunas_desempenho].to_parquet('sample_desempenho.parquet', index=False, engine='pyarrow')\n",
    "\n",
    "# Criar arquivos dtypes separados\n",
    "dtypes_gerenico = {col: str(microdados[col].dtype) for col in colunas_gerenicas if col in microdados.columns}\n",
    "dtypes_geral = {col: str(microdados[col].dtype) for col in colunas_geral if col in microdados.columns}\n",
    "dtypes_aspectos = {col: str(microdados[col].dtype) for col in colunas_aspectos_sociais if col in microdados.columns}\n",
    "dtypes_desempenho = {col: str(microdados[col].dtype) for col in colunas_desempenho if col in microdados.columns}\n",
    "\n",
    "# Usar json module em vez do pandas to_json para evitar problemas de serialização\n",
    "import json\n",
    "with open('dtypes_gerenico.json', 'w') as f:\n",
    "    json.dump(dtypes_gerenico, f)\n",
    "with open('dtypes_geral.json', 'w') as f:\n",
    "    json.dump(dtypes_geral, f)\n",
    "with open('dtypes_aspectos_sociais.json', 'w') as f:\n",
    "    json.dump(dtypes_aspectos, f)\n",
    "with open('dtypes_desempenho.json', 'w') as f:\n",
    "    json.dump(dtypes_desempenho, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivo = '../Iniciação Científica/Códigos/microdados_tratado.parquet'\n",
    "\n",
    "# microdados = pd.read_parquet(arquivo, engine='pyarrow',)\n",
    "\n",
    "# dtypes = pd.read_json(\"dtypes.json\", typ='series')\n",
    "# microdados = microdados.astype(dtypes)\n",
    "\n",
    "# microdados = microdados[colunas_desejadas]\n",
    "\n",
    "# microdados = microdados[(microdados['TP_PRESENCA_GERAL'] == 1) & (microdados['NU_MEDIA_GERAL'] != -1)]\n",
    "\n",
    "# microdados = microdados[microdados['NU_MEDIA_GERAL'] != -1]\n",
    "\n",
    "# microdados = microdados.sample(938488, random_state=42)\n",
    "\n",
    "# microdados.to_parquet('sample.parquet', index=False, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet('sample.parquet')\n",
    "# f = df.select_dtypes(include='float16').columns\n",
    "# i = df.select_dtypes(include='int16').columns\n",
    "\n",
    "# df[f] = df[f].astype('float64')\n",
    "# df[i] = df[i].astype('int64')\n",
    "# profile = ProfileReport(df, title=\"Analise microdados\")\n",
    "# profile.to_file(\"exploratoria_original.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
